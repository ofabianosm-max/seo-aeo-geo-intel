#!/usr/bin/env python3
"""
run_analysis.py â€” Orquestrador Principal
Ponto de entrada Ãºnico para executar a skill seo-aeo-geo-intel.
Detecta modo, verifica integraÃ§Ãµes, executa mÃ³dulos e gera relatÃ³rio Markdown.

Uso:
    python run_analysis.py --site seunegocio.com.br
    python run_analysis.py --site seunegocio.com.br --mode competitor --target rival1.com.br
    python run_analysis.py --site seunegocio.com.br --mode delta
    python run_analysis.py --site seunegocio.com.br --mode performance
"""

import os
import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# Adicionar scripts/ ao path
SCRIPTS_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPTS_DIR))

OUTPUT_DIR = Path(os.getenv("SEO_SKILL_OUTPUT_DIR", "./reports"))
CACHE_DIR  = Path(os.getenv("SEO_SKILL_CACHE_DIR", "./cache"))
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
CACHE_DIR.mkdir(parents=True, exist_ok=True)


# â”€â”€ Carregamento lazy de clientes de API â”€â”€
def get_tavily_client():
    key = os.getenv("TAVILY_API_KEY","")
    if not key:
        return None
    try:
        from tavily import TavilyClient
        return TavilyClient(api_key=key)
    except ImportError:
        print("âš ï¸  Instale tavily-python: pip install tavily-python")
        return None


def get_gsc_service():
    json_path = os.getenv("GSC_SERVICE_ACCOUNT_JSON","")
    if not json_path:
        return None
    try:
        from googleapiclient.discovery import build
        from google.oauth2 import service_account
        import json as jsonlib

        if Path(json_path).exists():
            creds = service_account.Credentials.from_service_account_file(
                json_path,
                scopes=["https://www.googleapis.com/auth/webmasters.readonly"]
            )
        else:
            info = jsonlib.loads(json_path)
            creds = service_account.Credentials.from_service_account_info(
                info,
                scopes=["https://www.googleapis.com/auth/webmasters.readonly"]
            )
        return build("searchconsole", "v1", credentials=creds)
    except Exception as e:
        print(f"âš ï¸  GSC: {e}")
        return None


# â”€â”€ ExecuÃ§Ã£o por mÃ³dulo â”€â”€
def run_pagespeed(url: str) -> dict:
    from pagespeed_fetcher import analyze
    return analyze(url)


def run_gsc(site: str, gsc_service, days: int = 30) -> dict:
    from gsc_fetcher import fetch_all
    return fetch_all(site, gsc_service, days=days)


def run_complaints(competitor: str, tavily) -> dict:
    from complaint_detective import analyze
    return analyze(competitor, tavily_client=tavily)


def run_tech_stack(url: str, pagespeed_data: dict = None) -> dict:
    from tech_stack_detector import analyze
    return analyze(url, pagespeed_data)


def run_prices(competitors: list, tavily) -> dict:
    from price_monitor import analyze
    return analyze(competitors, tavily)


def run_radar(site: str, keywords: list, competitors: list, tavily) -> dict:
    from new_entrant_radar import find_new_entrants
    return find_new_entrants(site, keywords, competitors, tavily_client=tavily)


def run_positioning(competitor: str, name: str, tavily, html: str = "") -> dict:
    from competitor_intel import analyze_competitor_positioning
    return analyze_competitor_positioning(competitor, name, tavily, html)


def run_lead_magnets(competitor: str, name: str, tavily) -> dict:
    from lead_magnet_spy import analyze
    return analyze(competitor, name, tavily)


def run_crawl(site: str, gsc_service) -> dict:
    from crawl_analyzer import analyze
    return analyze(site, gsc_service)


def run_internal_links(site: str, gsc_service, tavily) -> dict:
    from internal_link_analyzer import analyze
    return analyze(site, gsc_service, tavily)


def run_content_health(site: str, gsc_service, tavily) -> dict:
    from content_health import analyze
    return analyze(site, gsc_service, tavily)


def run_local_seo(site: str, business_name: str, city: str, tavily) -> dict:
    from local_seo_analyzer import analyze
    return analyze(site, business_name, city, tavily)


def run_backlinks(site: str, competitors: list) -> dict:
    from backlink_fetcher import analyze
    return analyze(site, competitors)


# â”€â”€ Construtor do relatÃ³rio Markdown â”€â”€
def build_report(data: dict, mode: str, site: str) -> str:
    from output.markdown_builder import build
    return build(data, mode, site)


# â”€â”€ Fluxo principal â”€â”€
def run(args):
    site   = args.site.replace("https://","").replace("http://","").rstrip("/")
    mode   = args.mode
    days   = args.days
    competitors = [c.strip() for c in args.competitors.split(",")] if args.competitors else []
    target = args.target  # para modo competitor

    print(f"\n{'='*55}")
    print(f"  seo-aeo-geo-intel v2.2")
    print(f"  Site: {site} | Modo: {mode}")
    print(f"{'='*55}\n")

    # Verificar integraÃ§Ãµes
    tavily  = get_tavily_client()
    gsc     = get_gsc_service()
    has_ps  = bool(os.getenv("PAGESPEED_API_KEY",""))

    print("ğŸ“¡ IntegraÃ§Ãµes:")
    print(f"  {'âœ…' if tavily  else 'âŒ'} Tavily API")
    print(f"  {'âœ…' if gsc     else 'âŒ'} Google Search Console")
    print(f"  {'âœ…' if has_ps  else 'âš ï¸ '} PageSpeed API {'(estimativa)' if not has_ps else ''}")
    print()

    if not tavily and not gsc:
        print("âŒ Nenhuma API disponÃ­vel. Configure TAVILY_API_KEY ou GSC_SERVICE_ACCOUNT_JSON.")
        sys.exit(1)

    data = {
        "meta": {
            "skill_version": "2.2",
            "site": site,
            "mode": mode,
            "start_time": datetime.now().isoformat(),
            "days": days,
            "competitors_monitored": competitors,
        },
        "modules": {},
        "skipped": [],
        "warnings": [],
    }

    site_url = f"https://{site}"

    # â”€â”€ MODO: full â”€â”€
    if mode == "full":
        print("ğŸš€ Iniciando anÃ¡lise completa...\n")

        # PageSpeed do seu site
        if has_ps:
            print("ğŸ“Š MÃ³dulo: PageSpeed")
            data["pagespeed"] = run_pagespeed(site_url)
        else:
            data["skipped"].append({"module": "pagespeed", "reason": "PAGESPEED_API_KEY nÃ£o configurada"})

        # GSC
        if gsc:
            print("\nğŸ“Š MÃ³dulo: GSC (dados do seu site)")
            data["gsc"] = run_gsc(site, gsc, days=days)
        else:
            data["skipped"].append({"module": "gsc", "reason": "GSC nÃ£o configurado"})

        # Concorrentes (detectar automaticamente se nÃ£o informados)
        if not competitors and tavily:
            print("\nğŸ” Detectando concorrentes automaticamente...")
            # Busca simples para encontrar quem compete
            try:
                niche_query = data.get("gsc", {}).get("top_keywords", [])[:3]
                if niche_query:
                    results = tavily.search(" ".join(niche_query[:2]), max_results=5)
                    auto_competitors = []
                    for r in results.get("results",[]):
                        d = r.get("url","").replace("https://","").replace("http://","").split("/")[0]
                        if d and d != site and d not in auto_competitors:
                            auto_competitors.append(d)
                    competitors = auto_competitors[:3]
                    print(f"  â†’ {len(competitors)} concorrente(s) detectado(s): {', '.join(competitors)}")
            except Exception:
                pass

        # Tech stack (seu site + concorrentes)
        if tavily or has_ps:
            print("\nğŸ“Š MÃ³dulo 7: Tech Stack")
            tech_results = [run_tech_stack(site_url, data.get("pagespeed"))]
            for c in competitors:
                tech_results.append(run_tech_stack(f"https://{c}"))
            data["modules"]["tech_stack"] = tech_results

        # ReclamaÃ§Ãµes dos concorrentes
        if tavily and competitors:
            print("\nğŸ“Š MÃ³dulo 5: Detetive de ReclamaÃ§Ãµes")
            data["modules"]["complaints"] = [run_complaints(c, tavily) for c in competitors]

        # Iscas dos concorrentes
        if tavily and competitors:
            print("\nğŸ“Š MÃ³dulo 6: EspiÃ£o de Iscas")
            data["modules"]["lead_magnets"] = [run_lead_magnets(c, "", tavily) for c in competitors]

        # PreÃ§os
        if tavily and competitors:
            print("\nğŸ“Š MÃ³dulo 8: Benchmark de PreÃ§os")
            data["modules"]["prices"] = run_prices(competitors, tavily)

        # Posicionamento + Canais
        if tavily and competitors:
            print("\nğŸ“Š MÃ³dulos 10+11: Posicionamento e Canais")
            data["modules"]["positioning"] = [run_positioning(c, "", tavily) for c in competitors]

        # Radar de entrantes
        if tavily and gsc:
            print("\nğŸ“Š MÃ³dulo 9: Radar de Entrantes")
            top_kws = [k["query"] for k in data.get("gsc",{}).get("top_keywords",[])[:10]]
            data["modules"]["radar"] = run_radar(site, top_kws, competitors, tavily)
        else:
            data["skipped"].append({"module": "radar", "reason": "Requer GSC + Tavily"})

        # SEO TÃ©cnico
        if gsc:
            print("\nğŸ“Š MÃ³dulo 12: SEO TÃ©cnico (Crawl & IndexaÃ§Ã£o)")
            data["modules"]["seo_tecnico"] = run_crawl(site, gsc)

        # Links Internos
        if gsc:
            print("\nğŸ“Š MÃ³dulo 13: Links Internos")
            data["modules"]["internal_links"] = run_internal_links(site, gsc, tavily)
        else:
            data["skipped"].append({"module": "internal_links", "reason": "Requer GSC"})

        # SaÃºde do ConteÃºdo
        if gsc:
            print("\nğŸ“Š MÃ³dulo 15: SaÃºde do ConteÃºdo")
            data["modules"]["content_health"] = run_content_health(site, gsc, tavily)
        else:
            data["skipped"].append({"module": "content_health", "reason": "Requer GSC"})

        # Backlinks (opcional)
        if os.getenv("AHREFS_API_KEY") or os.getenv("SEMRUSH_API_KEY"):
            print("\nğŸ“Š MÃ³dulo 14: Backlinks")
            data["modules"]["backlinks"] = run_backlinks(site, competitors)
        else:
            data["skipped"].append({"module": "backlinks", "reason": "Ahrefs e Semrush nÃ£o configurados"})

        # Local SEO (condicional)
        if args.local_seo and tavily:
            print("\nğŸ“Š MÃ³dulo 16: Local SEO")
            data["modules"]["local_seo"] = run_local_seo(site, args.business_name or site, args.city or "", tavily)

    # â”€â”€ MODO: performance â”€â”€
    elif mode == "performance":
        if has_ps:
            data["pagespeed"] = run_pagespeed(site_url)
        if tavily and competitors:
            data["modules"]["tech_stack"] = [run_tech_stack(f"https://{c}") for c in competitors[:3]]
        if gsc:
            data["modules"]["seo_tecnico"] = run_crawl(site, gsc)

    # â”€â”€ MODO: competitor â”€â”€
    elif mode == "competitor":
        target_domain = target or (competitors[0] if competitors else None)
        if not target_domain:
            print("âŒ Informe --target DOMINIO para o modo competitor")
            sys.exit(1)

        if tavily:
            ps_data = run_pagespeed(f"https://{target_domain}") if has_ps else {}
            data["modules"]["tech_stack"]   = [run_tech_stack(f"https://{target_domain}", ps_data)]
            data["modules"]["complaints"]   = [run_complaints(target_domain, tavily)]
            data["modules"]["lead_magnets"] = [run_lead_magnets(target_domain, "", tavily)]
            data["modules"]["prices"]       = run_prices([target_domain], tavily)
            data["modules"]["positioning"]  = [run_positioning(target_domain, "", tavily)]

    # â”€â”€ MODO: delta â”€â”€
    elif mode == "delta":
        if gsc:
            data["gsc"] = run_gsc(site, gsc, days=7)
        if tavily and competitors:
            # Delta sÃ³ verifica tech stack e reclamaÃ§Ãµes (leve)
            data["modules"]["complaints"] = [run_complaints(c, tavily) for c in competitors[:2]]

    # â”€â”€ MODO: keywords â”€â”€
    elif mode == "keywords":
        if gsc:
            data["gsc"] = run_gsc(site, gsc, days=days)
        if gsc and tavily:
            data["modules"]["content_health"] = run_content_health(site, gsc, tavily)

    # â”€â”€ MODO: technical â”€â”€
    elif mode == "technical":
        if has_ps:
            data["pagespeed"] = run_pagespeed(site_url)
        if gsc:
            data["modules"]["seo_tecnico"]    = run_crawl(site, gsc)
            data["modules"]["internal_links"] = run_internal_links(site, gsc, tavily)

    # â”€â”€ Gerar relatÃ³rio Markdown â”€â”€
    data["meta"]["end_time"] = datetime.now().isoformat()

    print("\nğŸ“ Gerando relatÃ³rio Markdown...")
    report_md = build_report(data, mode, site)

    # Salvar
    date_str = datetime.now().strftime("%Y-%m-%d")
    filename = f"relatorio-{date_str}-{site}-{mode}.md"
    output_path = OUTPUT_DIR / filename
    output_path.write_text(report_md, encoding="utf-8")

    # Salvar baseline para modo delta
    if mode == "full":
        baseline_path = CACHE_DIR / f"baseline-{site}.json"
        baseline_data = {
            "date": date_str,
            "gsc_summary": data.get("gsc", {}).get("summary", {}),
            "pagespeed_mobile": data.get("pagespeed", {}).get("mobile", {}).get("scores", {}),
            "competitors": competitors,
        }
        baseline_path.write_text(json.dumps(baseline_data, ensure_ascii=False, indent=2))
        print(f"  â†’ Baseline salvo: {baseline_path}")

    print(f"\nâœ… RelatÃ³rio salvo: {output_path}")
    print(f"   MÃ³dulos executados: {len(data['modules'])}")
    print(f"   Pulados: {len(data['skipped'])}")

    if data["skipped"]:
        print("\nâ­ï¸  MÃ³dulos pulados:")
        for s in data["skipped"]:
            print(f"   â€¢ {s['module']}: {s['reason']}")

    return str(output_path)


def main():
    parser = argparse.ArgumentParser(
        description="seo-aeo-geo-intel v2.2 â€” AnÃ¡lise de InteligÃªncia Digital",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
  python run_analysis.py --site seunegocio.com.br
  python run_analysis.py --site seunegocio.com.br --mode performance
  python run_analysis.py --site seunegocio.com.br --mode competitor --target rival.com.br
  python run_analysis.py --site seunegocio.com.br --mode delta
  python run_analysis.py --site seunegocio.com.br --competitors rival1.com.br,rival2.com.br
        """
    )
    parser.add_argument("--site",         required=True, help="Seu domÃ­nio (ex: seunegocio.com.br)")
    parser.add_argument("--mode",         default="full",
                        choices=["full","delta","competitor","keywords","performance","technical","local"],
                        help="Modo de execuÃ§Ã£o (padrÃ£o: full)")
    parser.add_argument("--target",       default="", help="DomÃ­nio alvo para modo competitor")
    parser.add_argument("--competitors",  default="", help="Concorrentes conhecidos (vÃ­rgula)")
    parser.add_argument("--days",         type=int, default=30, help="PerÃ­odo GSC em dias (padrÃ£o: 30)")
    parser.add_argument("--local-seo",    action="store_true", help="Ativar mÃ³dulo de Local SEO")
    parser.add_argument("--business-name",default="", help="Nome comercial para Local SEO")
    parser.add_argument("--city",         default="", help="Cidade para Local SEO")
    args = parser.parse_args()

    run(args)


if __name__ == "__main__":
    main()
