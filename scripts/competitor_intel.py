#!/usr/bin/env python3
"""
competitor_intel.py â€” MÃ³dulos 10 e 11
MÃ³dulo 10: AnÃ¡lise de posicionamento (promessa, inimigo, prova, garantia, proposta Ãºnica)
MÃ³dulo 11: Mapa de canais e anÃºncios (pixels ativos, canais usados, copy de ads)
"""

import os
import re
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

CACHE_DIR = Path(os.getenv("SEO_SKILL_CACHE_DIR", "./cache"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MÃ“DULO 10 â€” AnÃ¡lise de Posicionamento
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

POSITIONING_PATTERNS = {
    "main_promise": [
        r"(?:ajudamos?|ajuda)\s+(?:\w+\s+){1,8}(?:a\s+)?(.{20,80})",
        r"(?:transformamos?|transforme)\s+(.{20,80})",
        r"(?:a soluÃ§Ã£o|a plataforma|o sistema)\s+(?:que\s+)?(.{20,80})",
        r"(?:aumente|gere|conquiste|escale|automatize)\s+(.{20,80})",
        r"(?:NÃ³s|Nosso time|Nossa equipe)\s+(.{20,80})",
    ],
    "enemy_identified": [
        r"(?:esqueÃ§a|chega de|pare de|cansado de|sem mais)\s+(.{15,60})",
        r"(?:nunca mais|nÃ£o precisa mais)\s+(.{15,60})",
        r"(?:enquanto|diferente de|ao contrÃ¡rio de)\s+(?:outros|a maioria|concorrentes)\s+(.{20,60})",
    ],
    "proof_elements": [
        r"(\d+)\s*(?:clientes?|empresas?|marcas?)\s*(?:atendidas?|satisfeitos?)?",
        r"(\d+)\s*(?:anos?|meses?)\s*(?:de|no)\s*(?:mercado|experiÃªncia)",
        r"R\$\s*(\d[\d.,]+)\s*(?:em|de)\s*(?:resultados?|faturamento|vendas?|receita)",
        r"(\d+)%\s*(?:de|dos?|das?)\s*(?:clientes?|casos?|projetos?)",
        r"(?:case|caso)\s+(?:de sucesso|real):\s*(.{20,60})",
    ],
    "unique_value": [
        r"(?:Ãºnico|Ãºnica|exclusivo|exclusiva|sÃ³ nÃ³s|apenas nÃ³s|somente nÃ³s)\s+(.{20,80})",
        r"(?:a Ãºnica\s+(?:empresa|agÃªncia|plataforma|soluÃ§Ã£o))\s+(?:que|no Brasil|do Brasil)\s+(.{20,80})",
        r"(?:mÃ©todo|metodologia|framework|processo)\s+(?:proprietÃ¡rio|prÃ³prio|exclusivo)\s*:?\s*(.{10,60})",
    ],
}

POSITIONING_GAPS = [
    {"id": "no_deadline_guarantee",   "label": "Sem prazo garantido na promessa"},
    {"id": "no_roi_claim",            "label": "Sem ROI/resultado mensurÃ¡vel"},
    {"id": "no_enemy_identified",     "label": "NÃ£o identifica inimigo/dor explÃ­cita"},
    {"id": "no_unique_method",        "label": "Sem metodologia proprietÃ¡ria citada"},
    {"id": "no_social_proof_numbers", "label": "Sem nÃºmeros de prova social"},
    {"id": "generic_promise",         "label": "Promessa genÃ©rica (fÃ¡cil de imitar)"},
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MÃ“DULO 11 â€” Mapa de Canais e AnÃºncios
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHANNEL_SIGNALS = {
    "Google Ads": {
        "patterns": ["googleadservices.com", "AW-", "google_conversion", "gclid"],
        "icon": "ğŸ”µ",
    },
    "Meta Ads (Facebook/Instagram)": {
        "patterns": ["connect.facebook.net/en_US/fbevents", "fbq(", "_fbp", "facebook.com/tr"],
        "icon": "ğŸ”µ",
    },
    "TikTok Ads": {
        "patterns": ["analytics.tiktok.com", "tiktok-pixel", "_ttp", "ttq.load"],
        "icon": "âš«",
    },
    "LinkedIn Ads": {
        "patterns": ["snap.licdn.com", "linkedin.com/px", "_li_"],
        "icon": "ğŸ”µ",
    },
    "Pinterest Ads": {
        "patterns": ["pintrk(", "ct.pinterest.com"],
        "icon": "ğŸ”´",
    },
    "Taboola": {
        "patterns": ["trc.taboola.com", "_taboola"],
        "icon": "ğŸŸ¡",
    },
    "Outbrain": {
        "patterns": ["outbrain.com/pixel", "OBPixelID"],
        "icon": "ğŸŸ¡",
    },
    "YouTube Ads": {
        "patterns": ["gtag('config', 'AW-", "youtube.com/channel"],
        "icon": "ğŸ”´",
    },
}

ORGANIC_CHANNEL_SIGNALS = {
    "YouTube": {
        "queries": ["site:youtube.com {name}", "{name} canal youtube"],
        "icon": "ğŸ”´",
    },
    "Instagram": {
        "queries": ["site:instagram.com {name}", "{name} @instagram"],
        "icon": "ğŸ“¸",
    },
    "LinkedIn": {
        "queries": ["site:linkedin.com/company {domain}"],
        "icon": "ğŸ”µ",
    },
    "TikTok OrgÃ¢nico": {
        "queries": ["site:tiktok.com @{name}", "{name} tiktok"],
        "icon": "âš«",
    },
    "Pinterest OrgÃ¢nico": {
        "queries": ["site:pinterest.com {name}"],
        "icon": "ğŸ”´",
    },
    "Podcast": {
        "queries": ["{name} podcast spotify anchor"],
        "icon": "ğŸ™ï¸",
    },
}


def extract_positioning(text: str) -> dict:
    """Extrai elementos de posicionamento do texto da pÃ¡gina."""
    result = {}

    for element, patterns in POSITIONING_PATTERNS.items():
        found = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            found.extend(m.strip() for m in matches if len(m.strip()) > 15)
        result[element] = found[:3]  # top 3 por elemento

    return result


def detect_gaps(positioning: dict) -> list[str]:
    """Identifica quais elementos de posicionamento estÃ£o ausentes."""
    gaps = []

    if not positioning.get("main_promise"):
        gaps.append("no_roi_claim")

    if not positioning.get("enemy_identified"):
        gaps.append("no_enemy_identified")

    if not positioning.get("unique_value"):
        gaps.append("no_unique_method")

    if not positioning.get("proof_elements"):
        gaps.append("no_social_proof_numbers")

    # Verificar se a promessa menciona prazo
    promise_text = " ".join(positioning.get("main_promise", []))
    if not re.search(r"\d+\s*(?:dias?|semanas?|horas?|meses?)", promise_text):
        gaps.append("no_deadline_guarantee")

    return gaps


def detect_paid_channels(html: str) -> list[dict]:
    """Detecta pixels de anÃºncio no HTML."""
    channels = []
    for channel, data in CHANNEL_SIGNALS.items():
        for pattern in data["patterns"]:
            if pattern in html:
                channels.append({
                    "name": channel,
                    "icon": data["icon"],
                    "type": "paid",
                })
                break
    return channels


def detect_organic_channels(domain: str, name: str, tavily_client) -> list[dict]:
    """Detecta canais orgÃ¢nicos ativos via Tavily."""
    channels = []
    domain_clean = domain.replace("https://","").replace("http://","").split("/")[0]
    name_clean = name or domain_clean.replace(".com.br","").replace(".com","")

    for channel, data in ORGANIC_CHANNEL_SIGNALS.items():
        query = data["queries"][0].replace("{domain}", domain_clean).replace("{name}", name_clean)
        try:
            results = tavily_client.search(query, max_results=2, search_depth="basic")
            if results.get("results"):
                channels.append({
                    "name": channel,
                    "icon": data["icon"],
                    "type": "organic",
                    "evidence": results["results"][0].get("url",""),
                })
        except Exception:
            pass

    return channels


def analyze_competitor_positioning(
    competitor_domain: str,
    competitor_name: str = "",
    tavily_client=None,
    html: str = "",
) -> dict:
    """AnÃ¡lise completa de posicionamento de um concorrente."""
    if not tavily_client:
        return {"status": "skipped", "reason": "Tavily nÃ£o configurado"}

    domain = competitor_domain.replace("https://","").replace("http://","").split("/")[0]
    name = competitor_name or domain.replace(".com.br","").replace(".com","").title()

    print(f"  ğŸ§  Posicionamento: {name}", end=" ", flush=True)

    # Buscar homepage e pÃ¡ginas principais
    try:
        results = tavily_client.search(
            f'site:{domain} OR "{name}" promessa proposta valor diferencial',
            max_results=5,
            search_depth="advanced",
            include_domains=[domain],
        )
        page_content = " ".join(r.get("content","") for r in results.get("results",[]))
    except Exception:
        page_content = html

    positioning = extract_positioning(page_content)
    gaps = detect_gaps(positioning)

    paid_channels = detect_paid_channels(html)
    organic_channels = detect_organic_channels(domain, name, tavily_client) if tavily_client else []

    print(f"{len(paid_channels)} canais pagos | {len(gaps)} gaps de posicionamento")

    result = {
        "status": "ok",
        "domain": domain,
        "name": name,
        "fetched_at": datetime.now().isoformat(),
        # MÃ³dulo 10
        "positioning": positioning,
        "positioning_gaps": gaps,
        # MÃ³dulo 11
        "paid_channels": paid_channels,
        "organic_channels": organic_channels,
        "total_channels": len(paid_channels) + len(organic_channels),
    }

    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    cache_file = CACHE_DIR / f"positioning-{domain}-{datetime.now().strftime('%Y-%m-%d')}.json"
    cache_file.write_text(json.dumps(result, ensure_ascii=False, indent=2))

    return result


def identify_channel_gaps(results: list[dict]) -> list[dict]:
    """Identifica canais onde nenhum concorrente estÃ¡ presente."""
    all_channels = set()
    for r in results:
        if r.get("status") != "ok":
            continue
        for c in r.get("paid_channels", []) + r.get("organic_channels", []):
            all_channels.add(c["name"])

    major_channels = ["YouTube", "TikTok OrgÃ¢nico", "LinkedIn", "Instagram",
                      "Google Ads", "Meta Ads (Facebook/Instagram)", "Podcast"]

    gaps = []
    for ch in major_channels:
        if ch not in all_channels:
            gaps.append({
                "channel": ch,
                "label": f"ğŸ† Canal livre â€” nenhum concorrente presente em {ch}",
                "opportunity": "Primeiros nesse canal podem dominar com menor CAC",
            })

    return gaps


def to_markdown_module10(results: list[dict]) -> str:
    """Gera seÃ§Ã£o Markdown do MÃ³dulo 10."""
    lines = ["## MÃ“DULO 10 â€” ANÃLISE DE POSICIONAMENTO", ""]

    for r in results:
        if r.get("status") != "ok":
            continue

        name = r.get("name", r.get("domain",""))
        pos = r.get("positioning", {})
        gaps = r.get("positioning_gaps", [])

        lines.append(f"### {name}")
        lines.append("")
        lines.append("| Elemento | Detectado |")
        lines.append("|---|---|")

        labels = {
            "main_promise": "Promessa principal",
            "enemy_identified": "Inimigo/dor identificada",
            "proof_elements": "Elementos de prova",
            "unique_value": "Proposta Ãºnica",
        }

        for key, label in labels.items():
            items = pos.get(key, [])
            val = items[0][:80] + "â€¦" if items else "âŒ NÃ£o detectado"
            lines.append(f"| {label} | {val} |")

        lines.append("")

        if gaps:
            lines.append(f"**Gaps de posicionamento ({len(gaps)} identificados):**")
            gap_labels = {g["id"]: g["label"] for g in POSITIONING_GAPS}
            for g in gaps:
                lines.append(f"â†’ ğŸ† {gap_labels.get(g, g)}")
            lines.append("")

        lines.append("---")
        lines.append("")

    return "\n".join(lines)


def to_markdown_module11(results: list[dict]) -> str:
    """Gera seÃ§Ã£o Markdown do MÃ³dulo 11."""
    lines = ["## MÃ“DULO 11 â€” MAPA DE CANAIS E ANÃšNCIOS", ""]

    # Tabela de canais por concorrente
    all_channel_names = set()
    for r in results:
        if r.get("status") == "ok":
            for c in r.get("paid_channels",[]) + r.get("organic_channels",[]):
                all_channel_names.add(c["name"])

    if all_channel_names:
        header = "| Concorrente | " + " | ".join(sorted(all_channel_names)) + " |"
        separator = "|---|" + "---|" * len(all_channel_names)
        lines.append(header)
        lines.append(separator)

        for r in results:
            if r.get("status") != "ok":
                continue
            active = set(c["name"] for c in r.get("paid_channels",[]) + r.get("organic_channels",[]))
            row = f"| {r.get('name', r.get('domain',''))} |"
            for ch in sorted(all_channel_names):
                row += " âœ… |" if ch in active else " âŒ |"
            lines.append(row)

        lines.append("")

    # Gaps de canal
    gaps = identify_channel_gaps(results)
    if gaps:
        lines.append("### ğŸ† Oportunidades de Canal")
        lines.append("")
        for g in gaps:
            lines.append(f"**{g['label']}**")
            lines.append(f"â†’ {g['opportunity']}")
            lines.append("")

    return "\n".join(lines)


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--competitor", required=True)
    parser.add_argument("--name", default="")
    parser.add_argument("--module", default="both", choices=["10","11","both"])
    args = parser.parse_args()

    try:
        from tavily import TavilyClient
        client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
    except Exception:
        client = None

    result = analyze_competitor_positioning(args.competitor, args.name, client)
    print(json.dumps(result, ensure_ascii=False, indent=2))
