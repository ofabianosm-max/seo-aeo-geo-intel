#!/usr/bin/env python3
"""
markdown_builder.py
Monta o relatÃ³rio final em Markdown estruturado a partir dos dados
coletados por todos os mÃ³dulos. Ã‰ o Ãºnico ponto de saÃ­da da skill.

Segue a especificaÃ§Ã£o definida em references/output-spec.md.
"""

import json
import os
import sys
from datetime import datetime, date
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

OUTPUT_DIR = Path(os.getenv("SEO_SKILL_OUTPUT_DIR", "./reports"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _fmt_score(score) -> str:
    if score is None:
        return "N/D"
    s = int(score)
    if s >= 90: return f"{s}/100 ğŸ†"
    if s >= 75: return f"{s}/100 âœ…"
    if s >= 50: return f"{s}/100 ğŸŸ¡"
    if s >= 25: return f"{s}/100 ğŸ”´"
    return f"{s}/100 ğŸ’€"


def _fmt_delta(curr, prev) -> str:
    if curr is None or prev is None:
        return "N/D"
    delta = curr - prev
    if delta > 0:   return f"+{delta} â†‘"
    if delta < 0:   return f"{delta} â†“"
    return "0 â†’"


def _severity_order(issue: dict) -> int:
    sev = issue.get("severity", "")
    if "CRÃTICO" in sev: return 0
    if "ALTO"    in sev: return 1
    if "MÃ‰DIO"   in sev: return 2
    return 3


def _today() -> str:
    return date.today().isoformat()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SeÃ§Ãµes do relatÃ³rio
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_frontmatter(ctx: dict) -> str:
    site       = ctx.get("site", "")
    modo       = ctx.get("mode", "full")
    modules    = ctx.get("modules_executed", [])
    skipped    = ctx.get("modules_skipped", [])
    start_date = ctx.get("start_date", "")
    end_date   = ctx.get("end_date", _today())
    baseline   = ctx.get("baseline_date", "")

    skip_block = ""
    if skipped:
        lines = []
        for s in skipped:
            if isinstance(s, dict):
                lines.append(f"  - id: {s['id']}\n    motivo: \"{s['reason']}\"")
            else:
                lines.append(f"  - id: {s}")
        skip_block = "modulos_pulados:\n" + "\n".join(lines)
    else:
        skip_block = "modulos_pulados: []"

    baseline_line = f"baseline_anterior: {baseline}" if baseline else ""

    return f"""---
skill: seo-aeo-geo-intel
versao: "2.2"
modo: {modo}
site: {site}
data: {_today()}
periodo_analise_inicio: {start_date}
periodo_analise_fim: {end_date}
modulos_executados: {json.dumps(modules)}
{skip_block}
{baseline_line}
---"""


def _build_header(ctx: dict) -> str:
    site  = ctx.get("site", "")
    start = ctx.get("start_date", "")
    end   = ctx.get("end_date", _today())
    return (
        f"# RelatÃ³rio de InteligÃªncia Digital â€” {site}\n"
        f"**Data:** {_today()} | **PerÃ­odo:** {start} a {end}\n"
    )


def _build_executive_summary(ctx: dict) -> str:
    scores = ctx.get("scores", {})
    prev   = ctx.get("scores_previous", {})

    def row(label, key):
        curr  = scores.get(key)
        p     = prev.get(key)
        delta = _fmt_delta(curr, p) if p else "â€”"
        return f"| {label} | {_fmt_score(curr)} | {_fmt_score(p)} | {delta} |"

    lines = [
        "## EXECUTIVE SUMMARY", "",
        "| DimensÃ£o | Score Atual | Score Anterior | Î” |",
        "|---|---|---|---|",
        row("SEO",       "seo"),
        row("AEO",       "aeo"),
        row("GEO",       "geo"),
        row("TÃ©cnico",   "technical"),
        row("ReputaÃ§Ã£o", "reputation"),
        "",
        f"**Principal oportunidade:** {ctx.get('main_opportunity', 'N/D')}",
        f"**Principal alerta:** {ctx.get('main_alert', 'N/D')}",
        f"**AÃ§Ã£o prioritÃ¡ria:** {ctx.get('priority_action', 'N/D')}",
    ]
    return "\n".join(lines)


def _build_pagespeed(data: dict) -> str:
    if not data or data.get("status") == "skipped":
        return (
            "## PAGESPEED INSIGHTS\n\n"
            "> â­ï¸ Pulado â€” PAGESPEED_API_KEY nÃ£o configurada.\n"
        )

    # Importar formatter do mÃ³dulo collector
    try:
        sys.path.insert(0, str(Path(__file__).parent))
        from pagespeed_fetcher import to_markdown
        return to_markdown(data)
    except ImportError:
        return "## PAGESPEED INSIGHTS\n\n> Dados disponÃ­veis mas formatter nÃ£o encontrado.\n"


def _build_seo_analysis(data: dict) -> str:
    if not data:
        return "## MÃ“DULO 1 â€” ANÃLISE SEO\n\n> â­ï¸ Pulado â€” GSC nÃ£o configurado.\n"

    score   = data.get("seo_score", 0)
    issues  = sorted(data.get("issues", []), key=_severity_order)
    queries = data.get("top_queries", [])

    lines = [
        f"## MÃ“DULO 1 â€” ANÃLISE SEO", "",
        f"### Score SEO: {_fmt_score(score)}", "",
    ]

    if issues:
        lines += ["### Issues Identificados", ""]
        for issue in issues[:10]:
            lines.append(f"{issue.get('severity','âšª')} â€” {issue.get('message','')}")
            if issue.get("action"):
                lines.append(f"  â†’ AÃ§Ã£o: {issue['action']}")
        lines.append("")

    if queries:
        lines += [
            "### Top 10 PÃ¡ginas por TrÃ¡fego (fonte: GSC)", "",
            "| URL | Clicks | ImpressÃµes | CTR | PosiÃ§Ã£o MÃ©dia |",
            "|---|---|---|---|---|",
        ]
        for q in queries[:10]:
            url  = q.get("url", q.get("query", ""))[:55]
            cl   = q.get("clicks", 0)
            imp  = q.get("impressions", 0)
            ctr  = f"{q.get('ctr', 0):.1f}%"
            pos  = q.get("position", 0)
            lines.append(f"| {url} | {cl} | {imp} | {ctr} | {pos} |")
        lines.append("")

    return "\n".join(lines)


def _build_complaints(data: dict) -> str:
    if not data:
        return "## MÃ“DULO 5 â€” DETETIVE DE RECLAMAÃ‡Ã•ES\n\n> â­ï¸ Pulado.\n"

    lines = ["## MÃ“DULO 5 â€” DETETIVE DE RECLAMAÃ‡Ã•ES", ""]

    for competitor, comp_data in data.items():
        rep_score = comp_data.get("reputation_score", 0)
        lines.append(f"### {competitor} â€” Score de ReputaÃ§Ã£o: {_fmt_score(rep_score)}")
        lines.append("")

        categories = comp_data.get("categories", {})
        total = comp_data.get("total_complaints", 0)
        if total > 0:
            lines += [
                "| Categoria | OcorrÃªncias | % do total |",
                "|---|---|---|",
            ]
            for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
                if count > 0:
                    pct = round(count / total * 100)
                    lines.append(f"| {cat.replace('_',' ').title()} | {count} | {pct}% |")
            lines.append("")

        snippets = comp_data.get("snippets", [])
        if snippets:
            lines.append("**ReclamaÃ§Ãµes Representativas:**")
            lines.append("")
            for s in snippets[:3]:
                lines.append(f"> \"{s.get('snippet','')[:200]}\"")
                lines.append(f"> â€” *{s.get('source','')}*")
                lines.append("")

        top_cat = comp_data.get("top_category")
        if top_cat:
            lines.append(
                f"ğŸ¯ **Oportunidade:** Principal falha de `{competitor}` Ã© "
                f"`{top_cat.replace('_',' ')}`. Use isso como diferencial direto no seu copy."
            )
            lines.append("")

    return "\n".join(lines)


def _build_tech_stack(data: dict) -> str:
    if not data:
        return "## MÃ“DULO 7 â€” RAIO-X TECNOLÃ“GICO\n\n> â­ï¸ Pulado.\n"

    lines = ["## MÃ“DULO 7 â€” RAIO-X TECNOLÃ“GICO", "",
             "### Stack por Empresa", "",
             "| Empresa | Framework / CMS | CDN | PageSpeed Mobile | ClassificaÃ§Ã£o |",
             "|---|---|---|---|---|"]

    for site, d in data.items():
        detected = d.get("detected", {})
        cms_fw   = next((k for k in ["nextjs","nuxtjs","gatsby","astro","react",
                                      "vue","svelte","angular","wordpress","wix",
                                      "webflow","squarespace","framer","shopify"]
                         if k in detected), "N/D")
        cdn_name = next((k for k in ["cloudflare","vercel","netlify","fastly","aws","azure"]
                         if k in detected), "NÃ£o detectado")
        ps_score = d.get("pagespeed_mobile", "N/D")
        classif  = d.get("classification", "N/D")
        lines.append(f"| {site} | {cms_fw} | {cdn_name} | {ps_score} | {classif} |")

    lines += ["", "### Plataformas de AnÃºncios Detectadas", ""]
    for site, d in data.items():
        ads = d.get("ad_platforms", [])
        if ads:
            lines.append(f"**{site}:** {', '.join(ads)}")

    lines.append("")
    return "\n".join(lines)


def _build_prices(data: dict) -> str:
    if not data:
        return "## MÃ“DULO 8 â€” BENCHMARK DE PREÃ‡OS\n\n> â­ï¸ Pulado.\n"

    lines = ["## MÃ“DULO 8 â€” BENCHMARK DE PREÃ‡OS", "",
             "### PreÃ§os Encontrados (fonte: Tavily)", ""]

    competitors = data.get("competitors", {})
    if not competitors:
        lines.append("> Nenhum preÃ§o publicado encontrado nos sites analisados.")
        lines.append("")
        return "\n".join(lines)

    lines += ["| Empresa | PreÃ§os Identificados |",
              "|---|---|"]
    for comp, comp_data in competitors.items():
        prices = comp_data.get("prices_found", [])
        if prices:
            lines.append(f"| {comp} | {' | '.join(prices[:5])} |")
        else:
            lines.append(f"| {comp} | NÃ£o publicado |")

    lines += ["",
              "ğŸ¯ **Gap identificado:** Verifique se algum concorrente nÃ£o publica preÃ§os â€” ",
              "isso pode indicar venda consultiva ou preÃ§o alto que nÃ£o suporta comparaÃ§Ã£o direta.",
              ""]

    return "\n".join(lines)


def _build_keywords(gsc_data: dict) -> str:
    if not gsc_data:
        return "## KEYWORDS\n\n> â­ï¸ Pulado â€” GSC nÃ£o configurado.\n"

    lines = ["## KEYWORDS", ""]

    # Monitor de posiÃ§Ãµes
    changes = gsc_data.get("changes", {})
    drops   = changes.get("drops", [])
    gains   = changes.get("gains", [])
    new_q   = changes.get("new_queries", [])

    if drops:
        lines += ["### âš ï¸ Alertas de Queda (fonte: GSC)", "",
                  "| Keyword | PosiÃ§Ã£o Anterior | PosiÃ§Ã£o Atual | Î” | Clicks Perdidos Est. |",
                  "|---|---|---|---|---|"]
        for d in drops[:10]:
            lines.append(
                f"| {d['query']} | {d['position_prev']} | "
                f"{d['position_curr']} | +{d['delta']} â†“ | "
                f"~{d.get('clicks_lost_est',0)}/mÃªs |"
            )
        lines.append("")

    if gains:
        lines += ["### ğŸ‰ Ganhos de PosiÃ§Ã£o (fonte: GSC)", "",
                  "| Keyword | PosiÃ§Ã£o Anterior | PosiÃ§Ã£o Atual | Î” |",
                  "|---|---|---|---|"]
        for g in gains[:10]:
            lines.append(
                f"| {g['query']} | {g['position_prev']} | "
                f"{g['position_curr']} | -{g['delta']} â†‘ |"
            )
        lines.append("")

    # Oportunidades
    opps = gsc_data.get("opportunities", {})
    opp_zone = opps.get("opportunity_zone", [])
    if opp_zone:
        lines += ["### ğŸ¯ Zona de Oportunidade â€” PosiÃ§Ãµes 8-20 (fonte: GSC)", "",
                  "| Keyword | PosiÃ§Ã£o | ImpressÃµes/mÃªs | CTR | AÃ§Ã£o |",
                  "|---|---|---|---|---|"]
        for o in opp_zone[:15]:
            acao = "Otimizar post existente" if o.get("clicks", 0) > 0 else "Criar conteÃºdo"
            lines.append(
                f"| {o['query']} | {o['position']} | "
                f"{o['impressions']} | {o['ctr']}% | {acao} |"
            )
        lines.append("")

    if new_q:
        lines += ["### ğŸ†• Novas Keywords Detectadas (fonte: GSC)", "",
                  "| Keyword | PosiÃ§Ã£o | ImpressÃµes/mÃªs | Clicks |",
                  "|---|---|---|---|"]
        for q in new_q[:10]:
            lines.append(
                f"| {q['query']} | {q['position']} | "
                f"{q['impressions']} | {q['clicks']} |"
            )
        lines.append("")

    return "\n".join(lines)


def _build_action_plan(ctx: dict) -> str:
    actions = ctx.get("action_plan", {})
    if not actions:
        # Gerar plano bÃ¡sico baseado nos issues coletados
        return _generate_default_plan(ctx)

    lines = ["## MÃ“DULO 4 â€” PLANO DE AÃ‡ÃƒO", ""]

    sprint_config = [
        ("sprint_1", "Sprint 1 â€” Quick Wins (Semana 1-2)"),
        ("sprint_2", "Sprint 2 â€” Crescimento (Semana 3-6)"),
        ("sprint_3", "Sprint 3 â€” Autoridade e GEO (Semana 7-12)"),
    ]

    for sprint_key, sprint_label in sprint_config:
        sprint_items = actions.get(sprint_key, [])
        if not sprint_items:
            continue
        lines += [f"### {sprint_label}", "",
                  "| # | AÃ§Ã£o | Impacto Estimado | EsforÃ§o | MÃ³dulo Origem |",
                  "|---|---|---|---|---|"]
        for i, item in enumerate(sprint_items, 1):
            sev    = item.get("severity", "ğŸŸ¢")
            action = item.get("action", "")
            impact = item.get("impact", "â€”")
            effort = item.get("effort", "MÃ©dio")
            module = item.get("module", "â€”")
            lines.append(f"| {sev} {i} | {action} | {impact} | {effort} | {module} |")
        lines.append("")

    return "\n".join(lines)


def _generate_default_plan(ctx: dict) -> str:
    """Gera plano de aÃ§Ã£o bÃ¡sico a partir dos issues coletados."""
    all_issues = ctx.get("all_issues", [])
    critical = [i for i in all_issues if "CRÃTICO" in i.get("severity", "")]
    high     = [i for i in all_issues if "ALTO"    in i.get("severity", "")]
    medium   = [i for i in all_issues if "MÃ‰DIO"   in i.get("severity", "")]

    lines = ["## MÃ“DULO 4 â€” PLANO DE AÃ‡ÃƒO", ""]

    if critical:
        lines += ["### Sprint 1 â€” Quick Wins (Semana 1-2)", "",
                  "| # | AÃ§Ã£o | EsforÃ§o |",
                  "|---|---|---|"]
        for i, issue in enumerate(critical[:5], 1):
            action = issue.get("action", issue.get("message", ""))
            lines.append(f"| ğŸ”´ {i} | {action} | Baixo-MÃ©dio |")
        lines.append("")

    if high:
        lines += ["### Sprint 2 â€” Crescimento (Semana 3-6)", "",
                  "| # | AÃ§Ã£o | EsforÃ§o |",
                  "|---|---|---|"]
        for i, issue in enumerate(high[:5], 1):
            action = issue.get("action", issue.get("message", ""))
            lines.append(f"| ğŸŸ¡ {i} | {action} | MÃ©dio |")
        lines.append("")

    if medium:
        lines += ["### Sprint 3 â€” Autoridade (Semana 7-12)", "",
                  "| # | AÃ§Ã£o | EsforÃ§o |",
                  "|---|---|---|"]
        for i, issue in enumerate(medium[:5], 1):
            action = issue.get("action", issue.get("message", ""))
            lines.append(f"| ğŸŸ¢ {i} | {action} | MÃ©dio-Alto |")
        lines.append("")

    return "\n".join(lines)


def _build_execution_metadata(ctx: dict) -> str:
    meta = {
        "skill_version":        "2.2",
        "execution_date":       datetime.now().isoformat(),
        "execution_duration_seconds": ctx.get("duration_seconds", 0),
        "data_sources":         ctx.get("data_sources", {}),
        "modules_executed":     ctx.get("modules_executed", []),
        "modules_skipped":      ctx.get("modules_skipped", []),
        "competitors_analyzed": ctx.get("competitors_analyzed", []),
        "warnings":             ctx.get("warnings", []),
    }
    return (
        "## METADADOS DE EXECUÃ‡ÃƒO\n\n"
        "```json\n"
        + json.dumps(meta, ensure_ascii=False, indent=2)
        + "\n```\n"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Builder principal
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build(ctx: dict, output_path: Path = None) -> str:
    """
    Monta o relatÃ³rio completo a partir do contexto de dados.

    ctx esperado:
      site, mode, start_date, end_date, scores, scores_previous,
      modules_executed, modules_skipped, data_sources, warnings,
      competitors_analyzed, duration_seconds,
      main_opportunity, main_alert, priority_action,
      action_plan, all_issues,

      # Dados por mÃ³dulo:
      pagespeed_data, seo_data, complaints_data, tech_data,
      prices_data, gsc_data
    """
    mode = ctx.get("mode", "full")

    if mode == "delta":
        report = _build_delta(ctx)
    elif mode == "competitor":
        report = _build_competitor(ctx)
    else:
        report = _build_full(ctx)

    # Salvar
    if output_path is None:
        site_clean = ctx.get("site", "unknown").replace("https://", "").replace("/", "-")
        filename   = f"relatorio-{_today()}-{site_clean}-{mode}.md"
        output_path = OUTPUT_DIR / filename

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(report, encoding="utf-8")
    print(f"âœ… RelatÃ³rio salvo em: {output_path}", file=sys.stderr)
    return report


def _build_full(ctx: dict) -> str:
    sections = [
        _build_frontmatter(ctx),
        "",
        _build_header(ctx),
        "---",
        "",
        _build_executive_summary(ctx),
        "---",
        "",
        _build_pagespeed(ctx.get("pagespeed_data", {})),
        "---",
        "",
        _build_seo_analysis(ctx.get("seo_data", {})),
        "---",
        "",
        _build_complaints(ctx.get("complaints_data", {})),
        "---",
        "",
        _build_tech_stack(ctx.get("tech_data", {})),
        "---",
        "",
        _build_prices(ctx.get("prices_data", {})),
        "---",
        "",
        _build_keywords(ctx.get("gsc_data", {})),
        "---",
        "",
        _build_action_plan(ctx),
        "---",
        "",
        _build_execution_metadata(ctx),
    ]
    return "\n".join(sections)


def _build_delta(ctx: dict) -> str:
    site       = ctx.get("site", "")
    baseline   = ctx.get("baseline_date", "")
    changes    = ctx.get("gsc_data", {}).get("changes", {})
    drops      = changes.get("drops", [])
    gains      = changes.get("gains", [])
    new_q      = changes.get("new_queries", [])
    competitor_changes = ctx.get("competitor_changes", [])

    lines = [
        _build_frontmatter(ctx), "",
        f"# Update Semanal â€” {site}",
        f"**Semana:** {baseline} a {_today()}",
        "", "---", "",
    ]

    if drops:
        lines.append("## ALERTAS")
        lines.append("")
        for d in drops[:5]:
            lines.append(
                f"ğŸ”´ CRÃTICO â€” \"{d['query']}\" caiu posiÃ§Ã£o "
                f"{d['position_prev']} â†’ {d['position_curr']} "
                f"(~{d.get('clicks_lost_est',0)} clicks/mÃªs perdidos)"
            )
        lines.append("")

    if competitor_changes:
        if "## ALERTAS" not in "\n".join(lines):
            lines.append("## ALERTAS")
            lines.append("")
        for c in competitor_changes:
            lines.append(f"ğŸŸ¡ ALTO â€” {c}")
        lines.append("")

    if gains:
        lines.append("## GANHOS")
        lines.append("")
        for g in gains[:5]:
            lines.append(
                f"ğŸ‰ \"{g['query']}\" subiu posiÃ§Ã£o "
                f"{g['position_prev']} â†’ {g['position_curr']}"
            )
        lines.append("")

    if new_q:
        lines += [
            "## NOVAS KEYWORDS (fonte: GSC)", "",
            "| Keyword | PosiÃ§Ã£o | ImpressÃµes/mÃªs | AÃ§Ã£o Sugerida |",
            "|---|---|---|---|",
        ]
        for q in new_q[:8]:
            acao = "Criar conteÃºdo" if q.get("clicks", 0) < 5 else "Otimizar"
            lines.append(f"| {q['query']} | {q['position']} | {q['impressions']} | {acao} |")
        lines.append("")

    if not drops and not gains and not new_q and not competitor_changes:
        lines.append("## SEM ALTERAÃ‡Ã•ES RELEVANTES")
        lines.append("")
        lines.append("Scores, keywords e concorrentes sem mudanÃ§as significativas nesta semana.")
        lines.append("")

    lines += ["---", "", _build_execution_metadata(ctx)]
    return "\n".join(lines)


def _build_competitor(ctx: dict) -> str:
    competitor = ctx.get("competitor_site", ctx.get("site", ""))
    reference  = ctx.get("reference_site", "")

    header = (
        f"# DossiÃª Competitivo â€” {competitor}\n"
        f"vs {reference} | {_today()}\n" if reference else
        f"# DossiÃª Competitivo â€” {competitor}\n"
        f"Data: {_today()}\n"
    )

    sections = [
        _build_frontmatter(ctx), "",
        header,
        "---", "",
        _build_tech_stack(ctx.get("tech_data", {})),
        "---", "",
        _build_complaints(ctx.get("complaints_data", {})),
        "---", "",
        _build_prices(ctx.get("prices_data", {})),
        "---", "",
        _build_execution_metadata(ctx),
    ]
    return "\n".join(sections)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Markdown Report Builder")
    parser.add_argument("--data",   required=True, help="Path para JSON com contexto")
    parser.add_argument("--output", help="Path de output do .md (opcional)")
    parser.add_argument("--stdout", action="store_true", help="Imprimir na stdout tambÃ©m")
    args = parser.parse_args()

    with open(args.data, encoding="utf-8") as f:
        ctx = json.load(f)

    output_path = Path(args.output) if args.output else None
    report = build(ctx, output_path)

    if args.stdout:
        print(report)
